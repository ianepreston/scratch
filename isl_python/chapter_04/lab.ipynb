{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "from IPython.display import display, Markdown\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printm(input_str):\n",
    "    display(Markdown(input_str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.6.2 The stock market data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sm.datasets.get_rdataset(\"Smarket\", \"ISLR\", cache=True).data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr().style.background_gradient(cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Volume\"].plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.6.2 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.get_dummies(df[\"Direction\"])[\"Up\"]\n",
    "X = df.drop(columns=[\"Direction\", \"Today\", \"Year\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit = sm.Logit(y, sm.add_constant(X)).fit()\n",
    "print(logit.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Access the coefficients and p values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit.pvalues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the first 10 predicted probabilities from the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_prob = logit.predict(sm.add_constant(X))\n",
    "predict_prob[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note to self, don't call fittedvalues for logistic regression, it just returns the dot product of the training exogenous variables and the coefficients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels = [\"Down\", \"Up\"] # took the Up dummy column as my independent variable, so 1 = Up\n",
    "predict_class = pd.Series(data=0, index=predict_prob.index)\n",
    "predict_class.loc[predict_prob > 0.5] = 1\n",
    "confusion_mat = confusion_matrix(y, predict_class)\n",
    "fig, ax = plot_confusion_matrix(conf_mat=confusion_mat, class_names=class_labels)\n",
    "ax.set_ylim(len(confusion_mat)-0.5, -0.5) # have to keep this in until matplotlib 3.1.2 comes out\n",
    "#https://github.com/matplotlib/matplotlib/issues/14751\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mask = df[\"Year\"] < 2005\n",
    "train_df = df.loc[train_mask].copy()\n",
    "test_df = df.loc[~train_mask].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = pd.get_dummies(train_df[\"Direction\"])[\"Up\"]\n",
    "X_train = train_df.drop(columns=[\"Direction\", \"Today\", \"Year\"])\n",
    "y_test = pd.get_dummies(test_df[\"Direction\"])[\"Up\"]\n",
    "X_test = test_df.drop(columns=[\"Direction\", \"Today\", \"Year\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit = sm.Logit(y_train, sm.add_constant(X_train)).fit()\n",
    "print(logit.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_prob = logit.predict(sm.add_constant(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels = [\"Down\", \"Up\"] # took the Up dummy column as my independent variable, so 1 = Up\n",
    "predict_class = pd.Series(data=0, index=predict_prob.index)\n",
    "predict_class.loc[predict_prob > 0.5] = 1\n",
    "confusion_mat = confusion_matrix(y_test, predict_class)\n",
    "fig, ax = plot_confusion_matrix(conf_mat=confusion_mat, class_names=class_labels)\n",
    "ax.set_ylim(len(confusion_mat)-0.5, -0.5) # have to keep this in until matplotlib 3.1.2 comes out\n",
    "#https://github.com/matplotlib/matplotlib/issues/14751\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(predict_class != y_test).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA\n",
    "Have to switch over to sklearn for this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = pd.get_dummies(train_df[\"Direction\"])[\"Up\"]\n",
    "X_train = train_df[[\"Lag1\", \"Lag2\"]]\n",
    "y_test = pd.get_dummies(test_df[\"Direction\"])[\"Up\"]\n",
    "X_test = test_df[[\"Lag1\", \"Lag2\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LinearDiscriminantAnalysis()\n",
    "lda.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printm(\"Prior probabilities of the groups: \")\n",
    "lda.priors_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The coefficients aren't the same as in R. Will have to figure out why that might be"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[R lda docs](https://stat.ethz.ch/R-manual/R-devel/library/MASS/html/lda.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels = [\"Down\", \"Up\"] # took the Up dummy column as my independent variable, so 1 = Up\n",
    "predict_class = lda.predict(X_test)\n",
    "confusion_mat = confusion_matrix(y_test, predict_class)\n",
    "fig, ax = plot_confusion_matrix(conf_mat=confusion_mat, class_names=class_labels)\n",
    "ax.set_ylim(len(confusion_mat)-0.5, -0.5) # have to keep this in until matplotlib 3.1.2 comes out\n",
    "#https://github.com/matplotlib/matplotlib/issues/14751\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It has the exact same confusion matrix though, not going to worry about the different coefficients much in that case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qda = QuadraticDiscriminantAnalysis()\n",
    "qda.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels = [\"Down\", \"Up\"] # took the Up dummy column as my independent variable, so 1 = Up\n",
    "predict_class = qda.predict(X_test)\n",
    "confusion_mat = confusion_matrix(y_test, predict_class)\n",
    "fig, ax = plot_confusion_matrix(conf_mat=confusion_mat, class_names=class_labels)\n",
    "ax.set_ylim(len(confusion_mat)-0.5, -0.5) # have to keep this in until matplotlib 3.1.2 comes out\n",
    "#https://github.com/matplotlib/matplotlib/issues/14751\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "knn.fit(X_train, y_train)\n",
    "predict_class = knn.predict(X_test)\n",
    "confusion_mat = confusion_matrix(y_test, predict_class)\n",
    "fig, ax = plot_confusion_matrix(conf_mat=confusion_mat, class_names=class_labels)\n",
    "ax.set_ylim(len(confusion_mat)-0.5, -0.5) # have to keep this in until matplotlib 3.1.2 comes out\n",
    "#https://github.com/matplotlib/matplotlib/issues/14751\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_train, y_train)\n",
    "predict_class = knn.predict(X_test)\n",
    "confusion_mat = confusion_matrix(y_test, predict_class)\n",
    "fig, ax = plot_confusion_matrix(conf_mat=confusion_mat, class_names=class_labels)\n",
    "ax.set_ylim(len(confusion_mat)-0.5, -0.5) # have to keep this in until matplotlib 3.1.2 comes out\n",
    "#https://github.com/matplotlib/matplotlib/issues/14751\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN on Caravan Insurance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sm.datasets.get_rdataset(\"Caravan\", \"ISLR\", cache=True).data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Want to use a standard scaler on all predictors so that they have a mean of 0 and a standard deviation of one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "pipe = make_pipeline(scaler, knn)\n",
    "y = pd.get_dummies(df[\"Purchase\"])[\"Yes\"]\n",
    "X = df.drop(columns=[\"Purchase\"])\n",
    "y_train = y.iloc[:1000]\n",
    "X_train = X.iloc[:1000]\n",
    "y_test = y.iloc[1000:]\n",
    "X_test = X.iloc[1000:]\n",
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipe.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(y_pred != y_test).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(y_test == 1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels = [\"No\", \"Yes\"]\n",
    "confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "fig, ax = plot_confusion_matrix(conf_mat=confusion_mat, class_names=class_labels)\n",
    "ax.set_ylim(len(confusion_mat)-0.5, -0.5) # have to keep this in until matplotlib 3.1.2 comes out\n",
    "#https://github.com/matplotlib/matplotlib/issues/14751\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model does the same thing for n_neighbors = 3 and 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'kneighborsclassifier__n_neighbors': [1, 3, 5]}\n",
    "search = GridSearchCV(pipe, param_grid, iid=False, cv=5)\n",
    "search.fit(X_train, y_train)\n",
    "print(\"Best parameter (CV score=%0.3f):\" % search.best_score_)\n",
    "print(search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = search.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "fig, ax = plot_confusion_matrix(conf_mat=confusion_mat, class_names=class_labels)\n",
    "ax.set_ylim(len(confusion_mat)-0.5, -0.5) # have to keep this in until matplotlib 3.1.2 comes out\n",
    "#https://github.com/matplotlib/matplotlib/issues/14751\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
