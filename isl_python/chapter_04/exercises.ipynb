{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10.\n",
    "\n",
    "this questions should be answered using the ```Weekly``` data set, which is part of the ```ISLR``` package. This data is similar in nature to the ```Smarket``` data from this chapter's lab, except that it contains 1,089 weekly returns for 21 years, from the beginning of 1900 to the end of 2010."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "from IPython.display import display, Markdown\n",
    "pd.options.display.max_rows = 999\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printm(input_str):\n",
    "    display(Markdown(input_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sm.datasets.get_rdataset(\"Weekly\", \"ISLR\", cache=True).data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a)\n",
    "Produce some numerical and graphical summaries of the ```Weekly``` data. Do there appear to be any patterns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df[\"Today\"] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cdf = df.reset_index().melt(value_vars=[\"Lag1\", \"Lag2\", \"Lag3\", \"Lag4\", \"Today\"], id_vars=\"index\")\n",
    "# sns.lineplot(x=\"index\", y=\"value\", hue=\"variable\", data=cdf);\n",
    "# Realized this is dumb, X is too squished so they all just overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr().style.background_gradient(cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Today\"].plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Volume\"].plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretty weak correlations, except between volume and year, which we can observe from the above plot is generally trending upward (although declining near the end there.\n",
    "\n",
    "From looking at the weekly returns plot the series is plausibly stationary. Mean definitely looks stable over time, the volatility might be increasing with time though.\n",
    "\n",
    "No missing values and the summary statistics all look good. For example, Today and the week lag of today have almost identical summary statistics, as you'd expect for series that are only off by two observations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b)\n",
    "\n",
    "Use the full data set to perform a logistic regression with ```Direction``` as the response and the five lag variables plus ```Volume``` as predictors. Use the summary function to print the results. Do any of the predictors appear to be statistically significant? If so, which ones?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[\"Direction\"] == \"Up\"\n",
    "X = df[[f\"Lag{x}\" for x in range(1, 6)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit = sm.Logit(y, sm.add_constant(X)).fit()\n",
    "print(logit.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The intercept has a positive and statistically significant coefficient, suggesting returns are slightly more likely to be positive.\n",
    "\n",
    "Lag 2 is statistically significant and positive (only lag with a positive sign). Implying likelihood of a positive return in the current period increases the more positive returns were two weeks ago."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c) \n",
    "\n",
    "Compute the confusion matrix and overall fraction of correct predictions. Explain what the confusion matrix is telling you about the types of mistakes made by logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels = [\"Down\", \"Up\"] # took the Up dummy column as my independent variable, so 1 = Up\n",
    "predict_prob = logit.predict(sm.add_constant(X))\n",
    "predict_class = pd.Series(data=0, index=predict_prob.index)\n",
    "predict_class.loc[predict_prob > 0.5] = 1 # question didn't specify threshold so let's assume 50%\n",
    "confusion_mat = confusion_matrix(y, predict_class)\n",
    "fig, ax = plot_confusion_matrix(conf_mat=confusion_mat, class_names=class_labels)\n",
    "ax.set_ylim(len(confusion_mat)-0.5, -0.5) # have to keep this in until matplotlib 3.1.2 comes out\n",
    "#https://github.com/matplotlib/matplotlib/issues/14751\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = (predict_class == y).sum() / len(y)\n",
    "printm(f\"Model correctly predicted direction {accuracy:0.1%} of the time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The confusion matrix shows that the model is almost exclusively predicting an Up day, regardless of the true outcome. It looks like the positive intercept coefficient is dominating all the other factors in the model. Which is fine given their weak statistical results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## d)\n",
    "\n",
    "Now fit the logistic regression model using a training data period from 1990 to 2008, with ```Lag2``` as the only predictor. Compute the confusion matrix and the overall fraction of correct predictions for the held out data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df.loc[df[\"Year\"] <= 2008].copy()\n",
    "df_test = df.loc[df[\"Year\"] > 2008].copy()\n",
    "y_train = df_train[\"Direction\"] == \"Up\"\n",
    "y_test = df_test[\"Direction\"] == \"Up\"\n",
    "X_train = df_train[\"Lag2\"]\n",
    "X_test = df_test[\"Lag2\"]\n",
    "logit = sm.Logit(y_train, sm.add_constant(X_train)).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_prob = logit.predict(sm.add_constant(X_test))\n",
    "predict_class = pd.Series(data=0, index=predict_prob.index)\n",
    "predict_class.loc[predict_prob > 0.5] = 1 # question didn't specify threshold so let's assume 50%\n",
    "confusion_mat = confusion_matrix(y_test, predict_class)\n",
    "fig, ax = plot_confusion_matrix(conf_mat=confusion_mat, class_names=class_labels)\n",
    "ax.set_ylim(len(confusion_mat)-0.5, -0.5) # have to keep this in until matplotlib 3.1.2 comes out\n",
    "#https://github.com/matplotlib/matplotlib/issues/14751\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## e)\n",
    "\n",
    "Repeat (d) using LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.values.reshape(-1, 1)\n",
    "X_test = X_test.values.reshape(-1, 1)\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "lda.fit(X_train, y_train)\n",
    "predict_class = lda.predict(X_test)\n",
    "confusion_mat = confusion_matrix(y_test, predict_class)\n",
    "fig, ax = plot_confusion_matrix(conf_mat=confusion_mat, class_names=class_labels)\n",
    "ax.set_ylim(len(confusion_mat)-0.5, -0.5) # have to keep this in until matplotlib 3.1.2 comes out\n",
    "#https://github.com/matplotlib/matplotlib/issues/14751\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## f)\n",
    "\n",
    "Repeat (d) using QDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "qda = QuadraticDiscriminantAnalysis()\n",
    "qda.fit(X_train, y_train)\n",
    "predict_class = qda.predict(X_test)\n",
    "confusion_mat = confusion_matrix(y_test, predict_class)\n",
    "fig, ax = plot_confusion_matrix(conf_mat=confusion_mat, class_names=class_labels)\n",
    "ax.set_ylim(len(confusion_mat)-0.5, -0.5) # have to keep this in until matplotlib 3.1.2 comes out\n",
    "#https://github.com/matplotlib/matplotlib/issues/14751\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## g)\n",
    "\n",
    "Repeat (d) using KNN with K=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "knn.fit(X_train, y_train)\n",
    "predict_class = knn.predict(X_test)\n",
    "confusion_mat = confusion_matrix(y_test, predict_class)\n",
    "fig, ax = plot_confusion_matrix(conf_mat=confusion_mat, class_names=class_labels)\n",
    "ax.set_ylim(len(confusion_mat)-0.5, -0.5) # have to keep this in until matplotlib 3.1.2 comes out\n",
    "#https://github.com/matplotlib/matplotlib/issues/14751\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# h)\n",
    "\n",
    "Which of these methods appears to provide the best results on this data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_pred = pd.Series(data=0, index=y_test.index)\n",
    "logit_pred.loc[logit.predict(sm.add_constant(X_test)) > 0.5] = 1 \n",
    "lda_pred = lda.predict(X_test)\n",
    "qda_pred = qda.predict(X_test)\n",
    "knn_pred = knn.predict(X_test)\n",
    "\n",
    "logit_accuracy = (logit_pred == y_test).sum() / len(y_test)\n",
    "lda_accuracy = (lda_pred == y_test).sum() / len(y_test)\n",
    "qda_accuracy = (qda_pred == y_test).sum() / len(y_test)\n",
    "knn_accuracy = (knn_pred == y_test).sum() / len(y_test)\n",
    "\n",
    "printm(f\"Logit accuracy: {logit_accuracy:0.1%}, LDA accuracy: {lda_accuracy:0.1%}, QDA accuracy: {qda_accuracy:0.1%}, KNN accuracy: {knn_accuracy:0.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logit and LDA are tied, with KNN the worst. I don't really trust any of these though."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## i)\n",
    "\n",
    "Experiment with different combinations of predictors, including possible transformations and interactions for each of the methods. Report the variables, method, and associated confusion matrix that appears to provide the best results on the held out data. Note that you should also experiment with values for K in the KNN classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pass."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11.\n",
    "\n",
    "In this problem, you will develop a model to predict whether a given car gets high or low gas mileage based on the ```Auto``` data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a)\n",
    "\n",
    "Create a binary variable, ```mpg01```, that contains a 1 if ```mpg``` contains a value above its median, and a 0 if ```mpg``` contains a value below its median."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (\n",
    "    sm.datasets.get_rdataset(\"Auto\", \"ISLR\", cache=True)\n",
    "    .data\n",
    "    .assign(mpg01=lambda df: df[\"mpg\"] > df[\"mpg\"].median())\n",
    ")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b)\n",
    "\n",
    "Explore the data graphically in order to investigate the association between ```mpg01``` and the other features. Which of the other features seems most likely to be useful in predicting ```mpg01```? Scatterplots and boxplots are be useful tools to answer this question. Describe your findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x=\"cylinders\", y=\"mpg\", kind=\"swarm\", data=df);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Increasing cylinders decreases mpg. Looks like there's a wider distribution among 4 cylinders, with fat right tails on 6 and 8. Also worth noting that there are very few 3 and 5 cylinder vehicles, so those categories might have to be collapsed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=\"displacement\", y=\"mpg\", data=df);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=\"horsepower\", y=\"mpg\", data=df);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Displacement and horsepower both have a negative and slightly nonlinear looking relationship with mpg. The relationship for both looks quite similar, which makes me wonder if displacement and horsepower are highly correlated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=\"horsepower\", y=\"displacement\", data=df);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like they are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=\"weight\", y=\"mpg\", data=df);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weight has a similar looking relationship to displacement and horsepower, although less clearly non-linear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=\"acceleration\", y=\"mpg\", data=df);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's a positive association here, but it's a lot weaker than the other variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x=\"year\", y=\"mpg\", kind=\"swarm\", data=df);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mpg appears to be improving over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x=\"origin\", y=\"mpg\", kind=\"swarm\", data=df);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 pretty clearly has a different distribution than 2 and 3, but it's less clear if 2 and 3 are distinct. 3 has the bulk of its distribution above 2, but the min and max are similar and the weights aren't obviously different. Might be worth combining. As a reminder 1 is American, 2 is European and 3 is Japanese."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c)\n",
    "\n",
    "Split the data into a training and a test set.\n",
    "\n",
    "The question doesn't ask but I'm going to do some transformations as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[\"mpg01\"].values\n",
    "X = pd.get_dummies(df[[\"cylinders\", \"displacement\", \"horsepower\", \"weight\", \"acceleration\", \"year\", \"origin\"]], columns=[\"origin\"], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## d)\n",
    "\n",
    "Perform LDA on the training data in order to predict ```mpg01``` using the variables that seemed most associated with ```mpg01``` in (b). What is the test error of the model obtained?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = [\"cylinders\", \"displacement\", \"weight\", \"year\", \"origin_2\", \"origin_3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LinearDiscriminantAnalysis()\n",
    "lda.fit(X_train[subset], y_train)\n",
    "y_pred = lda.predict(X_test[subset])\n",
    "accuracy = accuracy_score(y_pred, y_test)\n",
    "f1 = f1_score(y_pred, y_test)\n",
    "printm(f\"accuracy: {accuracy:0.7}\")\n",
    "printm(f\"f1: {f1:0.7}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## e)\n",
    "\n",
    "Perform QDA on the training data in order to predict ```mpg01``` using the variables that seemed most associated with ```mpg01``` in (b). What is the test error of the model obtained?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qda = QuadraticDiscriminantAnalysis()\n",
    "qda.fit(X_train[subset], y_train)\n",
    "y_pred = qda.predict(X_test[subset])\n",
    "accuracy = accuracy_score(y_pred, y_test)\n",
    "f1 = f1_score(y_pred, y_test)\n",
    "printm(f\"accuracy: {accuracy:0.7}\")\n",
    "printm(f\"f1: {f1:0.7}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## f)\n",
    "\n",
    "Perform Logistic regression on the training data in order to predict ```mpg01``` using the variables that seemed most associated with ```mpg01``` in (b). What is the test error of the model obtained?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit = LogisticRegression(fit_intercept=True, penalty=\"none\", solver=\"lbfgs\", max_iter=500)\n",
    "logit.fit(X_train[subset], y_train)\n",
    "y_pred = logit.predict(X_test[subset])\n",
    "accuracy = accuracy_score(y_pred, y_test)\n",
    "f1 = f1_score(y_pred, y_test)\n",
    "printm(f\"accuracy: {accuracy:0.7}\")\n",
    "printm(f\"f1: {f1:0.7}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## g)\n",
    "\n",
    "Perform KNN on the training data, with several values of K, in order to predict ```mpg01```. Use only the variables that seemed most associated with ```mpg01``` in (b). What test errors do you obtain? Which value of K seems to perform the best on this data set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "param_grid = {'n_neighbors': list(range(1,7))}\n",
    "search = GridSearchCV(knn, param_grid, iid=False, cv=5)\n",
    "search.fit(X_train, y_train)\n",
    "print(\"Best parameter (CV score=%0.3f):\" % search.best_score_)\n",
    "print(search.best_params_)\n",
    "y_pred = search.predict(X_test)\n",
    "accuracy = accuracy_score(y_pred, y_test)\n",
    "f1 = f1_score(y_pred, y_test)\n",
    "printm(f\"accuracy: {accuracy:0.7}\")\n",
    "printm(f\"f1: {f1:0.7}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12)\n",
    "\n",
    "This problem involves writing functions.\n",
    "\n",
    "a) Write a function, ```Power()```, that prints out the result of raising 2 to the 3rd power.\n",
    "b) Create a new function ```Power2()```, that allows you to pass *any* two numbers ```x``` and ```a```, and prints out the value ```x^a```.\n",
    "c) Using the ```Power2``` funcion you just wrote compute $10^3$, $8^17$, and $131^3$.\n",
    "d) Now create a new function, ```Power3()```, that actually returns the result ```x^a``` as a ```python``` object.\n",
    "e) Now using the ```Power3``` function, create a plot of $f(x)=x^2$. The *x*-axis should display a range of integers from 1 to 10, and the *y*-axis should display $x^2$. Label the axes appropriately, and use an appropriate title for the figure. Consider displaying either the *x*-axis, the *y*-axis, or both on the log-scale.\n",
    "f) Create a function, ```PlotPower``` that allows you to create a plot of ```x``` against ```x^a``` for a fixed ```a``` and for a range of values of ```x```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 13)\n",
    "\n",
    "Using the ```Boston``` data set, fit classification models in order to predict whether a given suburb has a crime rate above or below the median. Explore logistic regression, LDA,and KNN models using various subsets of the predictors. Describe your findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
