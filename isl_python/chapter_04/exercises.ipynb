{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10.\n",
    "\n",
    "this questions should be answered using the ```Weekly``` data set, which is part of the ```ISLR``` package. This data is similar in nature to the ```Smarket``` data from this chapter's lab, except that it contains 1,089 weekly returns for 21 years, from the beginning of 1900 to the end of 2010."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "from IPython.display import display, Markdown\n",
    "pd.options.display.max_rows = 999\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printm(input_str):\n",
    "    display(Markdown(input_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sm.datasets.get_rdataset(\"Weekly\", \"ISLR\", cache=True).data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a)\n",
    "Produce some numerical and graphical summaries of the ```Weekly``` data. Do there appear to be any patterns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df[\"Today\"] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cdf = df.reset_index().melt(value_vars=[\"Lag1\", \"Lag2\", \"Lag3\", \"Lag4\", \"Today\"], id_vars=\"index\")\n",
    "# sns.lineplot(x=\"index\", y=\"value\", hue=\"variable\", data=cdf);\n",
    "# Realized this is dumb, X is too squished so they all just overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr().style.background_gradient(cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Today\"].plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Volume\"].plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretty weak correlations, except between volume and year, which we can observe from the above plot is generally trending upward (although declining near the end there.\n",
    "\n",
    "From looking at the weekly returns plot the series is plausibly stationary. Mean definitely looks stable over time, the volatility might be increasing with time though.\n",
    "\n",
    "No missing values and the summary statistics all look good. For example, Today and the week lag of today have almost identical summary statistics, as you'd expect for series that are only off by two observations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b)\n",
    "\n",
    "Use the full data set to perform a logistic regression with ```Direction``` as the response and the five lag variables plus ```Volume``` as predictors. Use the summary function to print the results. Do any of the predictors appear to be statistically significant? If so, which ones?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[\"Direction\"] == \"Up\"\n",
    "X = df[[f\"Lag{x}\" for x in range(1, 6)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit = sm.Logit(y, sm.add_constant(X)).fit()\n",
    "print(logit.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The intercept has a positive and statistically significant coefficient, suggesting returns are slightly more likely to be positive.\n",
    "\n",
    "Lag 2 is statistically significant and positive (only lag with a positive sign). Implying likelihood of a positive return in the current period increases the more positive returns were two weeks ago."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c) \n",
    "\n",
    "Compute the confusion matrix and overall fraction of correct predictions. Explain what the confusion matrix is telling you about the types of mistakes made by logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels = [\"Down\", \"Up\"] # took the Up dummy column as my independent variable, so 1 = Up\n",
    "predict_prob = logit.predict(sm.add_constant(X))\n",
    "predict_class = pd.Series(data=0, index=predict_prob.index)\n",
    "predict_class.loc[predict_prob > 0.5] = 1 # question didn't specify threshold so let's assume 50%\n",
    "confusion_mat = confusion_matrix(y, predict_class)\n",
    "fig, ax = plot_confusion_matrix(conf_mat=confusion_mat, class_names=class_labels)\n",
    "ax.set_ylim(len(confusion_mat)-0.5, -0.5) # have to keep this in until matplotlib 3.1.2 comes out\n",
    "#https://github.com/matplotlib/matplotlib/issues/14751\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = (predict_class == y).sum() / len(y)\n",
    "printm(f\"Model correctly predicted direction {accuracy:0.1%} of the time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The confusion matrix shows that the model is almost exclusively predicting an Up day, regardless of the true outcome. It looks like the positive intercept coefficient is dominating all the other factors in the model. Which is fine given their weak statistical results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## d)\n",
    "\n",
    "Now fit the logistic regression model using a training data period from 1990 to 2008, with ```Lag2``` as the only predictor. Compute the confusion matrix and the overall fraction of correct predictions for the held out data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df.loc[df[\"Year\"] <= 2008].copy()\n",
    "df_test = df.loc[df[\"Year\"] > 2008].copy()\n",
    "y_train = df_train[\"Direction\"] == \"Up\"\n",
    "y_test = df_test[\"Direction\"] == \"Up\"\n",
    "X_train = df_train[\"Lag2\"]\n",
    "X_test = df_test[\"Lag2\"]\n",
    "logit = sm.Logit(y_train, sm.add_constant(X_train)).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_prob = logit.predict(sm.add_constant(X_test))\n",
    "predict_class = pd.Series(data=0, index=predict_prob.index)\n",
    "predict_class.loc[predict_prob > 0.5] = 1 # question didn't specify threshold so let's assume 50%\n",
    "confusion_mat = confusion_matrix(y_test, predict_class)\n",
    "fig, ax = plot_confusion_matrix(conf_mat=confusion_mat, class_names=class_labels)\n",
    "ax.set_ylim(len(confusion_mat)-0.5, -0.5) # have to keep this in until matplotlib 3.1.2 comes out\n",
    "#https://github.com/matplotlib/matplotlib/issues/14751\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## e)\n",
    "\n",
    "Repeat (d) using LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.values.reshape(-1, 1)\n",
    "X_test = X_test.values.reshape(-1, 1)\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "lda.fit(X_train, y_train)\n",
    "predict_class = lda.predict(X_test)\n",
    "confusion_mat = confusion_matrix(y_test, predict_class)\n",
    "fig, ax = plot_confusion_matrix(conf_mat=confusion_mat, class_names=class_labels)\n",
    "ax.set_ylim(len(confusion_mat)-0.5, -0.5) # have to keep this in until matplotlib 3.1.2 comes out\n",
    "#https://github.com/matplotlib/matplotlib/issues/14751\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## f)\n",
    "\n",
    "Repeat (d) using QDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "qda = QuadraticDiscriminantAnalysis()\n",
    "qda.fit(X_train, y_train)\n",
    "predict_class = qda.predict(X_test)\n",
    "confusion_mat = confusion_matrix(y_test, predict_class)\n",
    "fig, ax = plot_confusion_matrix(conf_mat=confusion_mat, class_names=class_labels)\n",
    "ax.set_ylim(len(confusion_mat)-0.5, -0.5) # have to keep this in until matplotlib 3.1.2 comes out\n",
    "#https://github.com/matplotlib/matplotlib/issues/14751\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## g)\n",
    "\n",
    "Repeat (d) using KNN with K=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "knn.fit(X_train, y_train)\n",
    "predict_class = knn.predict(X_test)\n",
    "confusion_mat = confusion_matrix(y_test, predict_class)\n",
    "fig, ax = plot_confusion_matrix(conf_mat=confusion_mat, class_names=class_labels)\n",
    "ax.set_ylim(len(confusion_mat)-0.5, -0.5) # have to keep this in until matplotlib 3.1.2 comes out\n",
    "#https://github.com/matplotlib/matplotlib/issues/14751\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# h)\n",
    "\n",
    "Which of these methods appears to provide the best results on this data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
