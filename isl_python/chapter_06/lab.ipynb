{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.5 Lab 1: Subset Selection Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.5.1 Best Subset Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we apply the best subset selection approach to the Hitters data. We wish to predict a baseball playerâ€™s Salary on the basis of various statistics associated with performance in the previous year. First of all, we note that the Salary variable is missing for some of the players. The is.na() function can be used to identify the missing observaitions. It returns a vector of the same length as the input vector, with a TRUE for any elements that are missing, and a FALSE for non-missing elements. The sum() function can then be used to count all of the missing elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sm.datasets.get_rdataset(\"Hitters\", \"ISLR\", cache=True).data.pipe(pd.get_dummies, columns=[\"League\", \"Division\", \"NewLeague\"], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Salary'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence we see that Salary is missing for 59 players. The na.omit() function removes all of the rows that have missing values in any variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=[\"Salary\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Salary'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The regsubsets() function (part of the leaps library) performs best subset selection by identifying the best model that contains a given number of predictors, where best is quantified using RSS. The syntax is the same as for lm(). The summary() command outputs the best set of variables for each model size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fun times, doesn't look like python has an equivalent library so I guess I'm coding this by hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[\"Salary\"]\n",
    "X = df.drop(columns=[\"Salary\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It's too slow to do all the way up to 8, let's just do it for 3. I'll get the point\n",
    "def modrsquared(coltuple, x, y):\n",
    "    lm = sm.OLS(y, sm.add_constant(x[[col for col in coltuple]])).fit()\n",
    "    return lm.rsquared\n",
    "\n",
    "def best_subset(max_vars, x, y):\n",
    "    models = dict()\n",
    "    for i in range(1, max_vars + 1):\n",
    "        col_opts = list(combinations(x.columns, i))\n",
    "        i_models = {cols: modrsquared(cols, x, y) for cols in col_opts}\n",
    "        best_cols = max(i_models.keys(), key=lambda k: i_models[k])\n",
    "        models[i] = best_cols\n",
    "    return models\n",
    "\n",
    "models = best_subset(4, X, y)\n",
    "models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The summary() function also returns $R^2$, RSS, adjusted $R^2$, $C_p$, and BIC. We can examine these to try to select the best overall model. For instance, we see that the $R^2$ statistic increases from 32%, when only one variable is included in the model, to almost 55 %, when all variables are included. As expected, the Plotting RSS, adjusted $R^2$, $C_p$, and BIC for all of the models at once will help us decide which model to select. Note the type=\"l\" option tells R to connect the plotted points with lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statsmodels has AIC but not C_p and since they're equivalent for OLS I'll just use AIC\n",
    "result_df = pd.DataFrame()\n",
    "for i in models.keys():\n",
    "    lm = sm.OLS(y, sm.add_constant(X[[col for col in models[i]]])).fit()\n",
    "    result_df.loc[i, \"R_square\"] = lm.rsquared\n",
    "    result_df.loc[i, \"adj_R_square\"] = lm.rsquared_adj\n",
    "    result_df.loc[i, \"RSS\"] = lm.mse_resid\n",
    "    result_df.loc[i, \"AIC\"] = lm.aic\n",
    "    result_df.loc[i, \"BIC\"] = lm.bic\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdf = result_df.reset_index().melt(id_vars=[\"index\"])\n",
    "sns.relplot(x=\"index\", y=\"value\", col=\"variable\", kind=\"line\", facet_kws={\"sharey\": False}, data=cdf);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.5.2 Forward and Backward Stepwise Selection\n",
    "We can also use the ```regsubsets()``` function to perform forward stepwise or backward stepwise selection, using the argument ```method=\"forward\"``` or ```method=\"backward\"```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sweet, we don't have this in python either. \n",
    "I'll base my implementation on [this](https://planspace.org/20150423-forward_selection_with_statsmodels/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_selected(x, y, maxvars):\n",
    "    \"\"\"Linear model designed by forward selection.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    x: DataFrame, potential exogenous variables\n",
    "    y: Series, variable to predict\n",
    "    \"\"\"\n",
    "    remaining = set(x.columns)\n",
    "    selected = []\n",
    "    models = {}\n",
    "    current_score, best_new_score = 0.0, 0.0\n",
    "    while remaining and len(selected) <= maxvars and current_score == best_new_score:\n",
    "        scores_with_candidates = []\n",
    "        for candidate in remaining:\n",
    "            X_candidate = sm.add_constant(x[selected + [candidate]])\n",
    "            score = sm.OLS(y, X_candidate).fit().rsquared_adj\n",
    "            scores_with_candidates.append((score, candidate))\n",
    "        scores_with_candidates.sort()\n",
    "        best_new_score, best_candidate = scores_with_candidates.pop()\n",
    "        if current_score < best_new_score:\n",
    "            remaining.remove(best_candidate)\n",
    "            selected.append(best_candidate)\n",
    "            current_score = best_new_score\n",
    "            models[len(selected)] = selected[:]\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forward_models = forward_selected(X, y, maxvars=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_selected(x, y):\n",
    "    \"\"\"Linear model designed by forward selection.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    x: DataFrame, potential exogenous variables\n",
    "    y: Series, variable to predict\n",
    "    \"\"\"\n",
    "    selected = list(x.columns)\n",
    "    models = {}\n",
    "    while len(selected) > 1:\n",
    "        scores_with_candidates = []\n",
    "        for candidate in selected:\n",
    "            X_candidate = sm.add_constant(x[selected].drop(columns=[candidate]))\n",
    "            score = sm.OLS(y, X_candidate).fit().rsquared_adj\n",
    "            scores_with_candidates.append((score, X_candidate))\n",
    "        scores_with_candidates.sort()\n",
    "#         if len(scores_with_candidates) < 19:\n",
    "#             return scores_with_candidates\n",
    "        best_score, best_candidate = scores_with_candidates.pop()\n",
    "        selected = list(best_candidate.drop(columns=[\"const\"]).columns)\n",
    "        models[len(selected)] = selected[:]\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backward_models = backward_selected(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backward_models[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forward_models[7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.5.3 Choosing Among Models Using the Validation Set Approach and Cross-Validation\n",
    "\n",
    "We just saw that it is possible to choose among a set of models of different sizes using $C_p$, BIC, and adjusted $R^2$. We will now consider how to do this using the validation set and cross-validation approaches.\n",
    "\n",
    "In order for these approaches to yield accurate estimates of the test error, we must use *only the training observations* to perform all aspects of model-fitting - including variable selection. Therefore, the determination of which model of a given size is best must be made using *only the training observations*. This point is subtle but important. If the full data set is used to perform the best subset selection step, the validation set errors and cross-validation errors that we obtain will not be accurate estimates of the test error. \n",
    "\n",
    "In order to use the validation set approach, we begin by splitting the observations into a training set and a test set. \n",
    "\n",
    "Now we apply ```regsubsets()``` to the training set in order to perform best subset selection.\n",
    "\n",
    "Notice that we subset the ```Hitters``` data frame directly in the call in order to access only the training subset of the data, using the expression ```Hitters[train,]```. We now compute the validation set error for the best model of each model size. We first make a model matrix from the test data.\n",
    "\n",
    "The ```model.matrix()``` function is used in many regression packages for building an \"X\" matrix from data. Now we run a loop, and for each size ```i``` we extract the coefficients from ```regfit.best``` for the best model of that size, multiply them into the appropriate columns of the test model matrix to form the predictions, and compute the test MSE.\n",
    "\n",
    "We find that the best model is the one that contains ten variables.\n",
    "\n",
    "This was a little tedious, partly because there is no ```predict()``` method for ```regsubsets()```. Since we will be using this function again, we can capture our steps above and write our own predict method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_subset(11, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# That takes forever to run so I'll just embed the results here\n",
    "best_subset_11 = {1: ('CRuns',),\n",
    " 2: ('Hits', 'CRBI'),\n",
    " 3: ('Hits', 'CRuns', 'PutOuts'),\n",
    " 4: ('AtBat', 'Hits', 'CRuns', 'PutOuts'),\n",
    " 5: ('Hits', 'CAtBat', 'CHits', 'CHmRun', 'PutOuts'),\n",
    " 6: ('Hits', 'CAtBat', 'CHits', 'CHmRun', 'PutOuts', 'Division_W'),\n",
    " 7: ('AtBat', 'Hits', 'CAtBat', 'CRuns', 'CRBI', 'PutOuts', 'League_N'),\n",
    " 8: ('AtBat',\n",
    "  'Hits',\n",
    "  'CAtBat',\n",
    "  'CRuns',\n",
    "  'CRBI',\n",
    "  'PutOuts',\n",
    "  'League_N',\n",
    "  'Division_W'),\n",
    " 9: ('AtBat',\n",
    "  'Hits',\n",
    "  'CAtBat',\n",
    "  'CRuns',\n",
    "  'CRBI',\n",
    "  'CWalks',\n",
    "  'PutOuts',\n",
    "  'League_N',\n",
    "  'Division_W'),\n",
    " 10: ('AtBat',\n",
    "  'Hits',\n",
    "  'Walks',\n",
    "  'CAtBat',\n",
    "  'CRuns',\n",
    "  'CRBI',\n",
    "  'CWalks',\n",
    "  'PutOuts',\n",
    "  'League_N',\n",
    "  'Division_W'),\n",
    " 11: ('AtBat',\n",
    "  'Hits',\n",
    "  'Walks',\n",
    "  'Years',\n",
    "  'CAtBat',\n",
    "  'CRuns',\n",
    "  'CRBI',\n",
    "  'CWalks',\n",
    "  'PutOuts',\n",
    "  'League_N',\n",
    "  'Division_W')}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summarizing, the next part is to do k-fold cross validation best model selection. For $k=10$ we want a $10x19$ matrix with the 10 folds and the best model on each fold for 1 through 19 variables. This is going to take forever to run so I'm going to skip it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.6 Lab 2: Ridge Regression and the Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the glmnet package in order to perform ridge regression and the lasso. The main function in this package is glmnet(), which can be used glmnet() to fit ridge regression models, lasso models, and more. This function has slightly different syntax from other model-fitting functions that we have encountered thus far in this book. In particular, we must pass in an x matrix as well as a y vector, and we do not use the y âˆ¼ x syntax. We will now perform ridge regression and the lasso in order to predict Salary on the Hitters data. Before proceeding ensure that the missing values have been removed rom the data as described above in section 6.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[\"Salary\"]\n",
    "X = df.drop(columns=[\"Salary\"])\n",
    "lambdas = 10**np.linspace(10,-2,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_sk = y.to_numpy().reshape(-1, 1)\n",
    "yscaler = StandardScaler(with_mean=False).fit(y_sk)\n",
    "y_rescale = yscaler.scale_\n",
    "y_scaled = yscaler.transform(y_sk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lam = len(X) * lambdas[49] / 2\n",
    "lam = lambdas[49]\n",
    "ridge = Ridge(alpha=lam, fit_intercept=True, normalize=True)\n",
    "ridge.fit(X, y)\n",
    "print(ridge.intercept_)\n",
    "ridge.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model.matrix() function is particularly useful for creating x; not only does it produce a matrix corresponding to the 19 predictors but it also automatically transforms any qualitative variables into dummy variables. The latter property is important because glmnet() can only take numerical, quantitative inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.6.1 Ridge Regression\n",
    "\n",
    "The ```glmnet()``` function has an alpha argument that determines what type\n",
    "of model is fit. If ```alpha=0``` then a ridge regression model is fit, and if ```alpha=1``` then a lasso model is fit. We first fit a ridge regression model.\n",
    "By default the glmnet() function performs ridge regression for an automatically selected range of $\\lambda$ values. However, here we have chosen to implement the function over a grid of values ranging from $\\lambda = 10^{10}$ to $\\lambda = 10^{âˆ’2}$, essentially covering the full range of scenarios from the null model containing only the intercept, to the least squares fit. As we will see, we can also compute model fits for a particular value of $\\lambda$ that is not one of the original grid values. Note that by default, the ```glmnet()``` function standardizes the variables so that they are on the same scale. To turn off this default setting,\n",
    "use the argument ```standardize=FALSE```.\n",
    "\n",
    "Associated with each value of $\\lambda$ is a vector of ridge regression coefficients, stored in a matrix that can be accessed by coef(). In this case, it is a 20Ã—100 matrix, with 20 rows (one for each predictor, plus an intercept) and 100\n",
    "columns (for for each value of $\\lambda$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Something about this isn't fitting the same, it's a difference in what they're optimizing for, see [StackOverflow](https://stats.stackexchange.com/questions/160096/what-are-the-differences-between-ridge-regression-using-rs-glmnet-and-pythons#160213)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambdas = 10**np.linspace(10,-2,100)\n",
    "ridge_coeffs = pd.DataFrame(index=lambdas, columns=X.columns)\n",
    "\n",
    "for lam in lambdas:\n",
    "    scaler = StandardScaler()\n",
    "    ridge = Ridge(normalize=False)\n",
    "    pipe = Pipeline([(\"scaler\", scaler), (\"ridge\", ridge)])\n",
    "    pipe.set_params(ridge__alpha=lam)\n",
    "    pipe.fit(X, y_scaled)\n",
    "    coef = pipe.named_steps[\"ridge\"].coef_\n",
    "    ridge_coeffs.loc[lam] = coef\n",
    "ridge_coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lam = 11_498  / 2\n",
    "scaler = StandardScaler(with_mean=False)\n",
    "ridge = Ridge(normalize=False)\n",
    "pipe = Pipeline([(\"scaler\", scaler), (\"ridge\", ridge)])\n",
    "pipe.set_params(ridge__alpha=lam)\n",
    "pipe.fit(X, y_scaled)\n",
    "coef = pipe.named_steps[\"ridge\"].coef_\n",
    "coef * pipe.named_steps.scaler.scale_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lam = 705  / 2\n",
    "scaler = StandardScaler(with_mean=False)\n",
    "ridge = Ridge(normalize=False)\n",
    "pipe = Pipeline([(\"scaler\", scaler), (\"ridge\", ridge)])\n",
    "pipe.set_params(ridge__alpha=lam)\n",
    "pipe.fit(X, y_scaled)\n",
    "coef = pipe.named_steps[\"ridge\"].coef_\n",
    "coef * pipe.named_steps.scaler.scale_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
