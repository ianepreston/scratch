{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paper Reproduction: \"Albertaâ€™s Fiscal Responses To Fluctuations In Non-Renewable-Resource Revenue\" in python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This is my replication of the empirical results, tables, and figures produced in a paper by Dr. Ergete Ferede, published by the University of Calgary school of public policy in Volume 11:24, September 2018.\n",
    "\n",
    "The original paper is here: [https://www.policyschool.ca/wp-content/uploads/2018/09/NRR-Ferede.pdf](https://www.policyschool.ca/wp-content/uploads/2018/09/NRR-Ferede.pdf)\n",
    "\n",
    "I chose this paper to reproduce for two reasons. The first is pragmatic; the data it uses is all publicly available, so I actually can. The second is that it describes a topic of importance in the province of Alberta, where I live.\n",
    "\n",
    "You can read the details of what the paper sets out to show in the paper itself, but in brief the idea is to show that provincial government spending increases in the year following an increase in non-renewable resource revenue, but it does not decrease accordingly in the year following declines in the same revenue source. This has a ratcheting effect on public finance that is a contributor to the \"royalty rollercoaster\" that is Alberta's public finance.\n",
    "\n",
    "In the following sections I'll go through the code necessary to extract and transform the data set used in the paper, as well as reproduce its key empirical results. Since most economists don't use python, and they make up a key part of my intended audience for this, I'll be adding comments to my code that explicitly describe what some of the functions and methods I'm calling do.\n",
    "\n",
    "I'm including all of the code necessary to produce this reproduction, since that's a big part of why I'm doing this exercise, but if you're just interested in seeing how my reproduced results compare to the original paper you can skip all the code blocks. You can find the code for this notebook on [my github](https://github.com/ianepreston/ferede_1124_reproduction)\n",
    "\n",
    "A surprising result of this reproduction is that I've identified a single data point error in the original paper that negates its results. Read on to find out what the error was and the impact it had on the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and data acquisition\n",
    "\n",
    "This section of the code loads required modules, downloads the required data sets, and reads them into DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "from itertools import chain\n",
    "from pathlib import Path\n",
    "\n",
    "import altair as alt\n",
    "from arch.unitroot import DFGLS, ADF, PhillipsPerron\n",
    "from IPython.display import Image\n",
    "import pandas as pd\n",
    "import pandas_datareader as pdr\n",
    "import requests\n",
    "import seaborn as sns\n",
    "import stats_can\n",
    "import statsmodels\n",
    "from statsmodels.tsa.api import VAR\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "alt.renderers.enable(\"jupyterlab\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by loading the required libraries that will be used to support the analysis. For reference here are links to the libraries that are being used:\n",
    "\n",
    "* [Pathlib](https://docs.python.org/3/library/pathlib.html)\n",
    "* [datetime](https://docs.python.org/3/library/datetime.html)\n",
    "* [requests](https://requests.readthedocs.io/en/master/)\n",
    "* [pandas](https://pandas.pydata.org/)\n",
    "* [pandas_datareader](https://pandas-datareader.readthedocs.io/en/latest/)\n",
    "* [numpy](https://numpy.org/)\n",
    "* [stats_can](https://stats-can.readthedocs.io/en/latest/)\n",
    "* [altair](https://altair-viz.github.io/)\n",
    "* [seaborn](https://seaborn.pydata.org/)\n",
    "* [arch](https://arch.readthedocs.io/en/latest/index.html)\n",
    "* [statsmodels](https://www.statsmodels.org/stable/index.html)\n",
    "* [matplotlib](https://matplotlib.org/stable/index.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Historical budget data\n",
    "\n",
    "Functions in this section are concerned with acquiring historical Alberta budget data and reading it into a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_budget_data() -> Path:\n",
    "    \"\"\"Download the excel file for the analysis from the policy school page.\n",
    "\n",
    "    Note the readme sheet on the first file. Credit to Kneebone and Wilkins for\n",
    "    assembling it, and policy school for hosting it.\n",
    "\n",
    "    Originally used this URL, but found it was missing some later heritage\n",
    "    contributions. After discussion with Dr. Kneebone an updated set has been provided\n",
    "    https://www.policyschool.ca/wp-content/uploads/2019/01/Provincial-Government-Budget-Data-January-2019FINAL-USE.xlsx\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pathlib.Path\n",
    "        A path object with the location and name of the data\n",
    "    \"\"\"\n",
    "    print('Downloading data set')\n",
    "\n",
    "    url = 'https://www.policyschool.ca/wp-content/uploads/2019/03/Provincial-Government-Budget-Data-March-2019.xlsx'\n",
    "    # send a request to the url for the file\n",
    "    response = requests.get(\n",
    "        url,\n",
    "        stream=True,\n",
    "        headers={'user-agent': None}\n",
    "    )\n",
    "    # create a path object for the file in the data folder above\n",
    "    # where this notebook is saved with the file named\n",
    "    # budget.xlsx for easy later access.\n",
    "    fname = Path('.').joinpath('data').joinpath('budgets.xlsx')\n",
    "    # write the response from the request to the file in the path specified above\n",
    "    with open (fname, 'wb') as outfile:\n",
    "        for chunk in response.iter_content(chunk_size=512):\n",
    "            if chunk: # filter out keep-alive new chunks\n",
    "                outfile.write(chunk)\n",
    "    # Return the location of the file so we can load it later easily\n",
    "    return fname\n",
    "\n",
    "\n",
    "def get_budget_file(force_update: bool=False) -> Path:\n",
    "    \"\"\"Get the budget file, downloading if required.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    force_update: bool\n",
    "        Download the data file even if you already have it\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pathlib.Path\n",
    "        A path object with the location and name of the data\n",
    "    \"\"\"\n",
    "    # This is where we're expecting the file to be saved if it exists\n",
    "    fname = Path('.').joinpath('data').joinpath('budgets.xlsx')\n",
    "    if not fname.exists() or force_update:\n",
    "        download_budget_data()\n",
    "    return fname\n",
    "\n",
    "\n",
    "def get_date_index(df: pd.DataFrame) -> pd.DatetimeIndex:\n",
    "    \"\"\"Helper function to turn budget year strings into datetimes.\n",
    "\n",
    "    The Fiscal year columns span across years, e.g. 1965-66. In order\n",
    "    to use all the date indexed functionality I want to convert them into\n",
    "    an actual datetime format. This function accomplishes that\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df: pd.DataFrame\n",
    "        The budget dataframe with the fiscal year style columns\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pd.DatetimeIndex\n",
    "        A datetime index showing January 1 of the beginning of each\n",
    "        fiscal year for each period.    \n",
    "    \"\"\"\n",
    "    date_index = pd.to_datetime(\n",
    "        df\n",
    "        .assign(year=lambda df: df['budget_yr'].str[0:4].astype(int))\n",
    "        .assign(month=1)\n",
    "        .assign(day=1)\n",
    "        [['year', 'month', 'day']]\n",
    "    )\n",
    "    return date_index\n",
    "\n",
    "\n",
    "def read_ab_budget() -> pd.DataFrame:\n",
    "    \"\"\"Read Alberta budget data.\n",
    "\n",
    "    Downloads the data if necessary, reads it in and gives\n",
    "    the variables easier to work with names\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Alberta's revenue and expenditure tables\n",
    "    \"\"\"\n",
    "    # Get the budget file, download if necessary  using functions\n",
    "    # defined above\n",
    "    fname = get_budget_file()\n",
    "    df = (\n",
    "        pd.read_excel(\n",
    "            fname,\n",
    "            sheet_name='Alberta',\n",
    "            # column titles are spaced over 3 rows\n",
    "            header=3,\n",
    "            # first column of data is B\n",
    "            index_col=1,\n",
    "            # there's a big footnote at the bottom we want to skip\n",
    "            skipfooter=21\n",
    "        )\n",
    "        # Because of the merged cells we get an empty first row\n",
    "        .loc[lambda x: x.index.notnull()]\n",
    "        # Not sure where the empty first column comes from but drop it\n",
    "        .drop(columns='Unnamed: 0')\n",
    "        .reset_index()\n",
    "        .rename(columns={\n",
    "            'index': 'budget_yr',\n",
    "            'Personal Income Tax': 'personal_income_tax',\n",
    "            'Corporation Income Tax': 'corporate_income_tax',\n",
    "            'Retail Sales Tax': 'retail_sales_tax',\n",
    "            'Federal Cash Transfers': 'federal_cash_transfers',\n",
    "            'Natural Resource Revenue': 'natural_resource_revenue',\n",
    "            'Other Own-Source Revenue': 'other_own_source_revenue',\n",
    "            'Total Revenue': 'total_revenue',\n",
    "            'Health': 'health_exp',\n",
    "            'Social Services': 'social_services_exp',\n",
    "            'Education': 'education_exp',\n",
    "            'Other Program Expenditures': 'other_program_exp',\n",
    "            'Total Program Expenditures': 'total_prog_exp',\n",
    "            'Debt Service': 'debt_service',\n",
    "            'Total  Expenditures': 'total_exp',\n",
    "            'Unnamed: 16': 'annual_deficit'\n",
    "        })\n",
    "        # Turn the fiscal year string into a datetime object\n",
    "        .assign(budget_dt=lambda df: get_date_index(df))\n",
    "        .set_index('budget_dt')\n",
    "    )\n",
    "    return df\n",
    "\n",
    "\n",
    "def read_heritage() -> pd.DataFrame:\n",
    "    \"\"\"Read deposits to the heritage trust fund from a separate table.\n",
    "\n",
    "    The paper nets out contributions to the heritage trust fund when they are\n",
    "    made, so we have to read them in to be able to net them out of resource revenue.\n",
    "\n",
    "    They're stored in the same sheet of the workbook, just down below the big table we\n",
    "    read in with the function above.\n",
    "    \"\"\"\n",
    "    fname = get_budget_file()\n",
    "    df = (\n",
    "        pd.read_excel(\n",
    "            fname,\n",
    "            sheet_name='Alberta',\n",
    "            # Have to manually specify column names because of\n",
    "            # how the table is laid out\n",
    "            header=None,\n",
    "            usecols='D:G',\n",
    "            names=['budget_yr', 'resource_allocation', 'deposits', 'advance_edu'],\n",
    "            skiprows=71,\n",
    "            skipfooter=1\n",
    "        )\n",
    "        # more fiddly cleaning because of how the table is set up\n",
    "        # there's a blank row between 1986-87 and when\n",
    "        # contributions resume in 2005-06\n",
    "        .loc[lambda df: ~df['budget_yr'].isna()]\n",
    "        .set_index('budget_yr')\n",
    "        # missing entries have 0 contributions for that\n",
    "        # category in that year\n",
    "        .fillna(0)\n",
    "        # The three columns are all counted the same\n",
    "        # for the purposes of this analysis, they just have\n",
    "        # different labels/classifications depending on the year\n",
    "        .assign(total_heritage=lambda df: df.sum(axis='columns'))\n",
    "        # Add a dummy variable to indicate heritage fund deposit years\n",
    "        .assign(heritage_dummy=1)\n",
    "        .reset_index()\n",
    "        # convert the fiscal year column to a datetime index\n",
    "        .assign(budget_dt=lambda df: get_date_index(df))\n",
    "        .drop(columns='budget_yr')\n",
    "        .set_index('budget_dt')\n",
    "    )\n",
    "    return df\n",
    "\n",
    "\n",
    "def clean_budget() -> pd.DataFrame:\n",
    "    \"\"\"Combine base budget with heritage deposits.\n",
    "\n",
    "    Pull all the logic together to create one dataframe with all the\n",
    "    fiscal data for the period of interest.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        The full nominal budget data set.\n",
    "    \"\"\"\n",
    "    budg = read_ab_budget()\n",
    "    heritage = read_heritage()\n",
    "    budg_clean = (\n",
    "        # Start with the budget dataframe\n",
    "        budg\n",
    "        # consolidate some revenue categories\n",
    "        .assign(other_revenue=lambda df: df[['retail_sales_tax', 'federal_cash_transfers', 'other_own_source_revenue']].sum(axis='columns'))\n",
    "        # Just keep the columns we still need\n",
    "        .reindex(columns=['personal_income_tax', 'corporate_income_tax', 'natural_resource_revenue', 'other_revenue', 'total_prog_exp', 'debt_service'])\n",
    "        # add in the heritage contributions data\n",
    "        .merge(heritage[['total_heritage', 'heritage_dummy']], how='left', left_index=True, right_index=True)\n",
    "        # Set contributions and the heritage dummy to 0 for years where there were no contributions\n",
    "        .fillna(0)\n",
    "        # Net out heritage contributions from natural resources revenue\n",
    "        .assign(natural_resource_revenue_before_heritage=lambda df: df['natural_resource_revenue'])\n",
    "        .assign(natural_resource_revenue=lambda df: df['natural_resource_revenue'] - df['total_heritage'])\n",
    "        # consolidate revenue\n",
    "        .assign(total_revenue=lambda df: df[['personal_income_tax', 'corporate_income_tax', 'natural_resource_revenue', 'other_revenue']].sum(axis='columns'))\n",
    "        # consolidate expenditure\n",
    "        .assign(total_expenditure=lambda df: df[['total_prog_exp', 'debt_service']].sum(axis='columns'))\n",
    "        # calculate the deficit\n",
    "        .assign(deficit=lambda df: df['total_expenditure'] - df['total_revenue'])\n",
    "        # make all the budget numbers floating point\n",
    "        .astype('float64')\n",
    "    )\n",
    "    return budg_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Real Per Capita budget\n",
    "\n",
    "All of the analysis in the paper is done in terms of real per-capita data. Functions in this section transform the nominal total budget numbers acquired in the previous section into real per-capita figures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def periodic_to_budget_annual(df: pd.DataFrame, index_name: str, year_periods: int = 4) -> pd.DataFrame:\n",
    "    \"\"\"Take a monthly or quarterly indexed dataframe and annualize it by budget period.\n",
    "\n",
    "    The inflation and population data we need to convert the budget into\n",
    "    real per-capita figures are monthly series. We need to get the average\n",
    "    population and price level for each fiscal year in the data set.\n",
    "\n",
    "    Rolling mean indexed on January year N+1 is the March to March\n",
    "    average population for fiscal year N\n",
    "    Applying a date offset of -1 year and taking only\n",
    "    January data of these rolling means gives us an average on the\n",
    "    same basis as the budget dates.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df: pandas.DataFrame\n",
    "        DataFrame to be piped into this function\n",
    "    index_name: str\n",
    "        The name of the date index\n",
    "    year_periods: int, default 4\n",
    "        4 for quarterly data (population), 12 for monthly (inflation)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        An annualized dataframe on a fiscal year basis for comparison\n",
    "        to annual budget figures.\n",
    "    \"\"\"\n",
    "    df = (\n",
    "        df\n",
    "        .copy()\n",
    "        .rolling(year_periods, closed='left')\n",
    "        .mean()\n",
    "        .reset_index()\n",
    "        .assign(budget_dt=lambda df: df[index_name] - pd.DateOffset(years=1))\n",
    "        .loc[lambda x: x['budget_dt'].dt.year >= 1965]\n",
    "        .loc[lambda x: x['budget_dt'].dt.month == 1]\n",
    "        .drop(columns=index_name)\n",
    "        .set_index('budget_dt')\n",
    "        .copy()\n",
    "    )\n",
    "    return df\n",
    "\n",
    "\n",
    "def per_capita_data() -> pd.DataFrame:\n",
    "    \"\"\"Read in population data to calculate per capita estimates.\n",
    "\n",
    "    Quarterly population estimates for Alberta from Statistics Canada\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Fiscal year annualized population estimates for Alberta over the\n",
    "        reference period.\n",
    "    \"\"\"\n",
    "    table = '17-10-0009-01'\n",
    "    df = (\n",
    "        stats_can.table_to_df(table, path='data')\n",
    "        .loc[lambda x: x['GEO'] == 'Alberta']\n",
    "        .loc[lambda x: x['REF_DATE'] >= '1965']\n",
    "        .set_index('REF_DATE')\n",
    "        [['VALUE']]\n",
    "        .rename(columns={'VALUE' : 'population'})\n",
    "        .pipe(periodic_to_budget_annual, 'REF_DATE', 4)\n",
    "    )\n",
    "    return df\n",
    "\n",
    "\n",
    "def inflation_data() -> pd.DataFrame:\n",
    "    \"\"\"Read in inflation data to calculate real dollar estimates.\n",
    "\n",
    "    The whole series is scaled so 2017 budget year is = 1\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Fiscal year annualized inflation data for Alberta over\n",
    "        the reference period. Normalized to 2017 = 1\n",
    "    \"\"\"\n",
    "    # Alberta inflation doesn't go back far enough, use Canada for earlier dates\n",
    "    vecs = ('v41692327', 'v41690973')\n",
    "    df = (\n",
    "        stats_can.vectors_to_df_local(vecs, path='data', start_date=dt.date(1965, 1, 1))\n",
    "        .rename(columns={'v41692327': 'ab_inflation', 'v41690973': 'ca_inflation'})\n",
    "    )\n",
    "    # fill in with Canadian inflation data where (early) Alberta inflation data is missing.\n",
    "    mask = df['ab_inflation'].isna()\n",
    "    # Could probably do some interpolation or scaling before this, but I looked\n",
    "    # at the raw series and they were pretty comparable\n",
    "    df.loc[mask, 'ab_inflation'] = df.loc[mask, 'ca_inflation']\n",
    "    df = (\n",
    "        df\n",
    "        .drop(columns='ca_inflation')\n",
    "        .pipe(periodic_to_budget_annual, 'REF_DATE', 12)\n",
    "    )\n",
    "    # Rescale to 2017 = 100 (this is fiscal year 2017,\n",
    "    # original may have done calendar year)\n",
    "    inf_2017 = float(df.loc['2017', 'ab_inflation'])\n",
    "    df = df / inf_2017\n",
    "    return df\n",
    "\n",
    "\n",
    "def budget_real_per_capita() -> pd.DataFrame:\n",
    "    \"\"\"Get budget data in real per-capita terms.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Budget data in real per-capita terms.\n",
    "    \"\"\"\n",
    "    # Read in budget data using the function defined in the \n",
    "    # previous section\n",
    "    clean_budget_df = clean_budget()\n",
    "    # Everything except the dummy variable gets turned into\n",
    "    # real per-capita terms\n",
    "    scale_cols = clean_budget_df.columns.drop('heritage_dummy').tolist()\n",
    "    # Get population\n",
    "    per_capita = per_capita_data()\n",
    "    # Get inflation\n",
    "    inflation = inflation_data()\n",
    "    # Combine the datasets, can just use assign because they all\n",
    "    # have a datetime index\n",
    "    dfpc = (\n",
    "        clean_budget_df\n",
    "        .assign(pop=per_capita)\n",
    "        .assign(cpi=inflation)\n",
    "    )\n",
    "    # rescale to real per capita\n",
    "    dfpc[scale_cols] = (\n",
    "        dfpc[scale_cols]\n",
    "        # original data was in millions of dollars\n",
    "        .mul(1_000_000)\n",
    "        # divide by population and inflation for\n",
    "        # real per-capita\n",
    "        .div(dfpc['pop'], axis='index')\n",
    "        .div(dfpc['cpi'], axis='index')\n",
    "    )\n",
    "    return dfpc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exogenous factors\n",
    "\n",
    "The paper lists the Alberta employment rate, the Alberta unemployment rate, and the CAD/USD exchange rate as exogenous factors included in the model. Functions in this section acquire that data. I had to do some fiddling to get long enough historical series for some of the factors as you'll note in the code. It's hard to say for sure how the original author sourced this data. I'll just have to compare my tables and charts to his to see if I got close enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_historical_cad_usd() -> pd.DataFrame:\n",
    "    \"\"\"Get exchange rates from before 1971.\n",
    "\n",
    "    FRED live data only goes back to 1971, I need a longer series\n",
    "    This was what I could find. It's annual only, so I can't do it on a budget\n",
    "    year basis, but hopefully it will be close enough\n",
    "\n",
    "    This whole function is just some gross munging to read in a table from a web page.\n",
    "    Once it's called we save it to the data folder so I don't have to re-call it every\n",
    "    time I run this notebook.\n",
    "    \"\"\"\n",
    "    url = 'https://fxtop.com/en/historical-exchange-rates.php?YA=1&C1=USD&C2=CAD&A=1&YYYY1=1953&MM1=01&DD1=01&YYYY2=2019&MM2=04&DD2=01&LANG=en'\n",
    "    df = pd.read_html(url)[29]\n",
    "    headers = df.iloc[0]\n",
    "    new_df  = (\n",
    "        pd.DataFrame(df.values[1:], columns=headers)\n",
    "        .rename(columns={'Year': 'year', 'Average USD/CAD': 'EXCAUS'})\n",
    "        .assign(month=1)\n",
    "        .assign(day=1)\n",
    "        .assign(budget_dt=lambda df: pd.to_datetime(df[['year', 'month', 'day']]))\n",
    "        .set_index('budget_dt')\n",
    "        .reindex(columns=['EXCAUS'])\n",
    "    )\n",
    "    new_df.to_csv('./data/early_cad_usd.csv')\n",
    "    return new_df\n",
    "\n",
    "\n",
    "def read_historical_cad_usd(force_update: bool = False) -> pd.DataFrame:\n",
    "    \"\"\"Get exchange rates before 1971.\n",
    "\n",
    "    This wraps the above function to read in the downloaded data\n",
    "    if it's available and download and then read it if required.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    force_update: bool\n",
    "        Download the data set even if you already have it\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Exchange rates from 1965 to 1971\n",
    "    \"\"\"\n",
    "    fname = Path('.').joinpath('data').joinpath('early_cad_usd.csv')\n",
    "    if not fname.exists() or force_update:\n",
    "        return download_historical_cad_usd()\n",
    "    else:\n",
    "        return pd.read_csv(fname).set_index('budget_dt')\n",
    "\n",
    "\n",
    "def download_cad_usd() -> pd.DataFrame:\n",
    "    \"\"\"Download monthly exchange data from FRED.\n",
    "\n",
    "    For most of the period of interest I can get monthly\n",
    "    data from FRED, so I'll do that where possible.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Most of the CAD/USD exchange data I need for this analysis.\n",
    "    \"\"\"\n",
    "    df = pdr.get_data_fred('EXCAUS', start=dt.date(1970, 1, 1))\n",
    "    df.to_csv('./data/cad_usd.csv')\n",
    "    return df\n",
    "\n",
    "\n",
    "def read_cad_usd(force_update=False):\n",
    "    \"\"\"Get monthly exchange data from FRED.\n",
    "\n",
    "    This wraps the above function to read in the downloaded data\n",
    "    if it's available and download and then read it if required.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    force_update: bool\n",
    "        Download the data set even if you already have it\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Exchange rate data\n",
    "    \"\"\"\n",
    "    fname = Path('.').joinpath('data').joinpath('cad_usd.csv')\n",
    "    if not fname.exists() or force_update:\n",
    "        return download_cad_usd()\n",
    "    else:\n",
    "        return pd.read_csv(fname, parse_dates=['DATE']).set_index('DATE')\n",
    "\n",
    "\n",
    "def annual_cad_usd() -> pd.DataFrame:\n",
    "    \"\"\"Full series of CAD/USD in fiscal year format.\n",
    "\n",
    "    Get FRED data and turn the monthly values into annualized on a budget\n",
    "    basis for as much as possible. Fill in the remainder with calendar annual\n",
    "    data from fxtop\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Exchange data on an annualized basis.\n",
    "    \"\"\"\n",
    "    # Create a datetime index of all the points we need\n",
    "    annual_date_range = pd.date_range('1964-01-01', '2018-01-01', freq='AS', name='budget_dt')\n",
    "    # Get the old annual stuff to fill in later\n",
    "    old_df = read_historical_cad_usd()\n",
    "    df = (\n",
    "        # get the monthly series\n",
    "        read_cad_usd()\n",
    "        # annualize it\n",
    "        .pipe(periodic_to_budget_annual, 'DATE', 12)\n",
    "        # add in all the missing dates we need\n",
    "        .reindex(annual_date_range)\n",
    "        # fill those missing dates from the old annual data set.\n",
    "        .fillna(old_df)\n",
    "    )\n",
    "    return df\n",
    "\n",
    "\n",
    "def stats_can_exog() -> pd.DataFrame:\n",
    "    \"\"\"Bring in exogenous StatsCan data. Employment and Unemployment rates.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Exogenous data required from StatsCan\n",
    "    \"\"\"\n",
    "    # Vectors for monthly series where available\n",
    "    ur_vec = \"v2064516\"\n",
    "    er_vec = \"v2064518\"\n",
    "    annual_date_range = pd.date_range('1964-01-01', '2018-01-01', freq='AS', name='budget_dt')\n",
    "    # for the earlier periods we only have annual data\n",
    "    old_df = (\n",
    "        stats_can.table_to_df('36-10-0345-01', path='data')\n",
    "        # Get Alberta data only\n",
    "        .loc[lambda x: x['GEO'] == 'Alberta']\n",
    "        # Keep only the categories we care about\n",
    "        .loc[lambda x: x['Economic indicators'].isin(['Population', 'Total employment', 'Unemployment rate'])]\n",
    "        # pivot so the year is the row and the variables are the columns\n",
    "        .pivot_table(index='REF_DATE', columns='Economic indicators', values='VALUE')\n",
    "        .rename(columns={'Unemployment rate': 'unemployment_rate'})\n",
    "        # calculate the employment rate\n",
    "        .assign(employment_rate=lambda x: (x['Total employment'] / x['Population']) * 100)\n",
    "        # drop the population, just used for calculating employment rate\n",
    "        .reindex(columns=['unemployment_rate', 'employment_rate'])\n",
    "        .rename_axis('budget_dt', axis='index')\n",
    "        .rename_axis(None, axis='columns')\n",
    "    )\n",
    "    # Get monthly data where available\n",
    "    df = (\n",
    "        stats_can.vectors_to_df_local([ur_vec, er_vec], path='data', start_date=dt.date(1964, 1, 1))\n",
    "        .rename(columns={ur_vec: 'unemployment_rate', er_vec: 'employment_rate'})\n",
    "        # annualize\n",
    "        .pipe(periodic_to_budget_annual, 'REF_DATE', 12)\n",
    "        # get the full range of data we want\n",
    "        .reindex(annual_date_range)\n",
    "        # fill in the gaps with the old annual series\n",
    "        .fillna(old_df)\n",
    "        # Not ideal but even the annual series doesn't go quite back\n",
    "        # far enough so we have to backfill the earliest available\n",
    "        # data point\n",
    "        .fillna(method='bfill')\n",
    "    )\n",
    "    return df\n",
    "\n",
    "\n",
    "def exogenous_variables() -> pd.DataFrame:\n",
    "    \"\"\"Bring in exogenous parameters together.\n",
    "\n",
    "    From the paper:\n",
    "    We also include other exogenous variables that are likely to affect\n",
    "    the provinceâ€™s budget. It is known that the various components of the\n",
    "    provincial budget can be influenced by the business cycle. Thus, following\n",
    "    Buettner and Wildsain (2006), we account for the potential effects of the\n",
    "    business cycle by including one-period lagged changes in the provincial\n",
    "    employment and unemployment rates. Another important exogenous factor\n",
    "    that is often cited in provincial budget documents as being important in\n",
    "    influencing the provincial governmentâ€™s oil royalty revenue is the Canadian-U.S.\n",
    "    dollar exchange rate. For this reason, we control for this factor by\n",
    "    including one period lagged changes in the Canadian-U.S. dollar exchange rate\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        All the necessary exogenous factors for reproducing the paper.\n",
    "    \"\"\"\n",
    "    cadusd = annual_cad_usd()\n",
    "    ur_er = stats_can_exog()\n",
    "    df = pd.concat([cadusd, ur_er], axis='columns')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Figures\n",
    "\n",
    "### Figure 1\n",
    "Page 5 of the report charts Non-renewable Resource Revenue, Total Expenditure, and Total Revenue. All are in per-capita 2017 dollars.\n",
    "Reproducing this chart will be a good starting check that my data extraction and transformation matches the original author's strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fig1(df: pd.DataFrame) -> alt.Chart:\n",
    "    \"\"\"Reproduce Figure 1 from the paper.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df: pd.DataFrame\n",
    "        A dataframe with non-renewable resource revenue, total expenditure, and total revenue time series\n",
    "    \"\"\"\n",
    "    chart_df = (\n",
    "        df\n",
    "        .loc['1970':'2016', ['natural_resource_revenue', 'total_revenue', 'total_expenditure']]\n",
    "        .rename(columns={\n",
    "            'natural_resource_revenue': 'Non-renewable Resource Revenue',\n",
    "            'total_revenue': 'Total Revenue',\n",
    "            'total_expenditure': 'Total Expenditure'\n",
    "        })\n",
    "        .reset_index()\n",
    "        .melt(id_vars='budget_dt')\n",
    "    )\n",
    "    c_domain = [\"Non-renewable Resource Revenue\", \"Total Expenditure\", \"Total Revenue\"]\n",
    "    c_range = [\"green\", \"red\", \"blue\"]\n",
    "    chart = (\n",
    "        alt.Chart(chart_df)\n",
    "        .mark_line()\n",
    "        .encode(\n",
    "            x=alt.X('budget_dt:T', axis=alt.Axis(title=None)),\n",
    "            y=alt.Y('value:Q', axis=alt.Axis(title='Per capita in 2017 dollars'), scale=alt.Scale(domain=(0, 14_000))),\n",
    "            color=alt.Color('variable:N', legend=alt.Legend(title=None, orient='bottom'), scale=alt.Scale(domain=c_domain, range=c_range))\n",
    "        )\n",
    "        .properties(width=1250, height=500)\n",
    "    )\n",
    "    return chart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the original chart from the paper:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename=\"img/ferede_fig_1.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here's mine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = budget_real_per_capita()\n",
    "fig1(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This graph looks very similar to the chart in the paper, with a notable exception of the 1976/1977 budget year. My chart shows Non-renewable Resource Revenue as slightly negative, whereas the original chart has it largely in line with 1975/1976 and 1977/1978. NRR is negative in my chart because I have netted out contributions to the Alberta Heritage Savings Trust Fund (AHSTF). To the best of my understanding, the original paper does the same, and the consistent values between the two in all other years supports that. Quoting the original paper:\n",
    "\n",
    ">The part of resource revenue that is saved in the AHSTF is not expected to influence the provincial governmentâ€™s spending and revenue-raising choices. For this reason, in our analysis, we exclude the part of the resource revenue that is saved in the AHSTF from the non-renewable-resource revenue data. \n",
    "\n",
    "For comparison, here is the same chart, but without netting AHSTF contributions from revenue:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_net_df = (\n",
    "    df\n",
    "    .assign(total_revenue=lambda df: df[\"total_revenue\"] + df[\"total_heritage\"])\n",
    "    .assign(natural_resource_revenue=lambda df: df[\"natural_resource_revenue\"] + df[\"total_heritage\"])\n",
    "    .assign(deficit=lambda df: df[\"total_expenditure\"] - df[\"total_revenue\"])\n",
    ")\n",
    "fig1(no_net_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1976/1977 more closely matches the original chart in the paper, but the remaining years in the period of mid 70s to mid 80s when there were significant contributions clearly do not match.\n",
    "Let's try one more where I just substitute that one year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_df = df.copy()\n",
    "heritage_76 = error_df.loc[\"1976\", \"total_heritage\"]\n",
    "error_df.loc[\"1976\", \"natural_resource_revenue\"] += heritage_76\n",
    "error_df.loc[\"1976\", \"total_revenue\"] += heritage_76\n",
    "error_df.loc[\"1976\", \"deficit\"] -= heritage_76\n",
    "fig1(error_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the original figure again for easier comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename=\"img/ferede_fig_1.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From eyeballing it that looks exactly like Figure 1 in the paper. It appears there's a data error in the original paper. For the rest of this analysis I'll compare both my base implementation of the data, as well as the one with the data error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 2\n",
    "\n",
    "Page 6 of the paper produces a scatter plot of Real per capita non-renewable resource revenue on the X axis vs. Real per capita budget balance on the Y, along with a linear trend fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fig2(df: pd.DataFrame) -> None:\n",
    "    \"\"\"Reproduce Figure 2 from the paper.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df: pd.DataFrame\n",
    "        The table with historical revenue and expenditure data.\n",
    "    \"\"\"\n",
    "    sns.set(rc={'figure.figsize':(11.7,8.27)})\n",
    "    chart_df = (\n",
    "        df\n",
    "        .loc['1970':'2016', ['natural_resource_revenue', 'deficit']]\n",
    "        .rename(columns={\n",
    "            'natural_resource_revenue': 'Non-renewable Resource Revenue',\n",
    "            'deficit': 'Deficit'\n",
    "        })\n",
    "        .assign(balance=lambda df: df['Deficit'] * -1)\n",
    "        .rename(columns={'balance': 'Budget Balance'})\n",
    "        .copy()\n",
    "    )\n",
    "    sns.regplot(x='Non-renewable Resource Revenue', y='Budget Balance', data=chart_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the original figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename=\"img/ferede_fig_2.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the figure using my original data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here's the figure using the version with a data error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2(error_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, this chart is more consistent with the dataframe where I don't net heritage fund contributions out of 1976 but do for all other years"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Specification and estimation\n",
    "\n",
    "This section combines the previously specified data extraction with transformations necessary to produce summary statistics, statistical tests, and the VAR model itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_df_levels(budg: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Combine real per capita budget data to get model data in levels.\n",
    "\n",
    "    lag exogenous variables (unemployment and employment rates, CAD/USD exchange)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    budg: pd.DataFrame\n",
    "        Budget data, either with or without data error\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Budget data combined with exogenous factors\n",
    "    \"\"\"\n",
    "    exog = exogenous_variables()\n",
    "    df = (\n",
    "        pd.concat([budg, exog], axis='columns')\n",
    "        .rename(columns={'total_prog_exp': 'program_expenditure', 'EXCAUS': 'cad_usd'})\n",
    "        .assign(ur_lag=lambda df: df['unemployment_rate'].shift(periods=1))\n",
    "        .assign(er_lag=lambda df: df['employment_rate'].shift(periods=1))\n",
    "        .assign(cad_usd_lag=lambda df: df['cad_usd'].shift(periods=1))\n",
    "        .reindex(columns=[\n",
    "            'program_expenditure', 'debt_service', 'corporate_income_tax',\n",
    "            'personal_income_tax', 'other_revenue', 'natural_resource_revenue',\n",
    "            'deficit', 'heritage_dummy', 'ur_lag', 'er_lag', 'cad_usd_lag'\n",
    "        ])\n",
    "    )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdfl = model_df_levels(df)\n",
    "mdfl_err = model_df_levels(error_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sumary statistics for key variables, 1970-71, 2016-17 in levels\n",
    "\n",
    "Prior to any modeling, let's compare the summary statistics for the data sets I've created against those in the paper:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number = \"{:0<4,.1f}\"\n",
    "percent = '{:.1%}'\n",
    "count = \"{:0.0f}\"\n",
    "\n",
    "\n",
    "def tbl1_level(model_df: pd.DataFrame):\n",
    "    \"\"\"Produce summary statistics of the input data in levels.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model_df: pd.DataFrame\n",
    "        Input data set\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.io.formats.style.Styler:\n",
    "        Nicely formatted summary statistics\n",
    "    \"\"\"\n",
    "    df = (\n",
    "        model_df\n",
    "        .loc['1970':'2016']\n",
    "        .copy()\n",
    "        .drop(columns=['heritage_dummy'])\n",
    "        .reindex(columns=[\n",
    "            'natural_resource_revenue', 'corporate_income_tax', 'personal_income_tax',\n",
    "            'other_revenue', 'debt_service', 'program_expenditure', 'deficit', 'ur_lag',\n",
    "            'er_lag', 'cad_usd_lag'\n",
    "        ])\n",
    "        .describe()\n",
    "        .T\n",
    "        .style.format({\n",
    "            'count': count,\n",
    "            'mean': number,\n",
    "            'std': number,\n",
    "            'min': number,\n",
    "            '25%': number,\n",
    "            '50%': number,\n",
    "            '75%': number,\n",
    "            'max': number\n",
    "        })\n",
    "    )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's Table 1 from the paper:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename=\"img/ferede_tbl_1.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's my summary of the top half"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbl1_level(mdfl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the same summary on the data with the introduced error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbl1_level(mdfl_err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the figures that I can validate against (exogenous variables aren't reported in the paper) are reasonably close. The one noted difference is the previously described outlier in natural resource revenue which leads to my minimum for that variable being significantly lower than in the paper. That large one goes away again if I introduce the same data error described above. My guess for the remaining small discrepancies are differences in calculating population or CPI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sumary statistics for key variables, 1970-71, 2016-17, first difference\n",
    "\n",
    "Reproduce the bottom half of table 1 from the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_df_first_diff(mdfl: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Produce the first difference of the level model df.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    mdfl: pd.DataFrame\n",
    "        The model dataframe in levels\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        The first differenced model dataframe\n",
    "    \"\"\"\n",
    "    df = (\n",
    "        mdfl\n",
    "        .diff()\n",
    "        .loc['1970':'2016']\n",
    "        .copy()\n",
    "        .assign(heritage_dummy=mdfl['heritage_dummy']) # don't want to lag diff this\n",
    "        .assign(constant=1)\n",
    "        .assign(zero=0)\n",
    "        .assign(nrrd=lambda df: df[['natural_resource_revenue', 'zero']].min(axis='columns'))\n",
    "        .assign(nrri=lambda df: df[['natural_resource_revenue', 'zero']].max(axis='columns'))\n",
    "        .reindex(columns=[\n",
    "            'natural_resource_revenue', 'nrri', 'nrrd', 'corporate_income_tax', 'personal_income_tax',\n",
    "            'other_revenue', 'debt_service', 'program_expenditure', 'deficit', 'ur_lag',\n",
    "            'er_lag', 'cad_usd_lag', 'heritage_dummy', 'constant'\n",
    "        ])\n",
    "    )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tbl1_diff(model_df: pd.DataFrame) -> pd.io.formats.style.Styler:\n",
    "    \"\"\"Produce summary statistics of the first differenced data set.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model_df: pd.DataFrame\n",
    "        Input data set\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.io.formats.style.Styler:\n",
    "        Nicely styled summary statistics\n",
    "    \"\"\"\n",
    "\n",
    "    df = (\n",
    "        model_df_first_diff(model_df)\n",
    "        .drop(columns=['heritage_dummy', 'constant'])\n",
    "        .describe()\n",
    "        .T\n",
    "        .style.format({\n",
    "            'count': count,\n",
    "            'mean': number,\n",
    "            'std': number,\n",
    "            'min': number,\n",
    "            '25%': number,\n",
    "            '50%': number,\n",
    "            '75%': number,\n",
    "            'max': number\n",
    "        })\n",
    "    )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's Table 1 from the paper again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename=\"img/ferede_tbl_1.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's mine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbl1_diff(mdfl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And with the data error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbl1_diff(mdfl_err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with everything so far, the data overall matches, and Natural Resource Revenue matches a lot better if I neglect to net out the heritage fund in 1976."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unit-Root Tests\n",
    "\n",
    "Table A1 in the paper shows the results of unit root tests for both the level and first differenced variables in the model. This section will reproduce those tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stationarity_tests(df: pd.DataFrame, first_diff: bool = False) -> pd.DataFrame:\n",
    "    \"\"\"Compute stationarity test statistics.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df: pd.DataFrame\n",
    "        The model input data\n",
    "    first_diff: bool, default False\n",
    "        Perform tests on first differenced version of the data\n",
    "    \"\"\"\n",
    "    if first_diff:\n",
    "        df = (\n",
    "            model_df_first_diff(df)\n",
    "            .drop(columns=[\"heritage_dummy\", \"constant\"])\n",
    "        )\n",
    "    else:\n",
    "        df = (\n",
    "            df\n",
    "            .loc['1970':'2016']\n",
    "            .copy()\n",
    "            .drop(columns=['heritage_dummy'])\n",
    "            .reindex(\n",
    "                columns=[\n",
    "                    'natural_resource_revenue',\n",
    "                    'corporate_income_tax',\n",
    "                    'personal_income_tax',\n",
    "                    'other_revenue',\n",
    "                    'debt_service',\n",
    "                    'program_expenditure',\n",
    "                    'deficit',\n",
    "                    'ur_lag',\n",
    "                    'er_lag',\n",
    "                    'cad_usd_lag',\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "    tests_dict = {'ADF': ADF, 'Phillips-Perron': PhillipsPerron, 'DF-GLS': DFGLS}\n",
    "    cols = df.columns\n",
    "    tests_df = pd.DataFrame()\n",
    "    for test_label, test in tests_dict.items():\n",
    "        for col in cols:\n",
    "            if test_label != 'Phillips-Perron':\n",
    "                col_test = test(df[col].dropna(), method='BIC')\n",
    "            else:\n",
    "                col_test = test(df[col].dropna())\n",
    "            test_val = col_test.stat\n",
    "            test_p = col_test.pvalue\n",
    "            test_summary = f'val: {test_val:0.3f}, p: {test_p:.1%}'\n",
    "            tests_df.loc[col, test_label] = test_summary\n",
    "    return tests_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the table from the paper:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename=\"img/ferede_tbl_a1.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is mine with my data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stationarity_tests(mdfl, first_diff=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stationarity_tests(mdfl, first_diff=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And with the error data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stationarity_tests(mdfl_err, first_diff=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stationarity_tests(mdfl_err, first_diff=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Documentation on the test tools I used can be found [here](https://arch.readthedocs.io/en/latest/unitroot/tests.html)\n",
    "\n",
    "There are some interesting differences. Most notable is that on the levels of the deficit series I reject the null hypothesis of a unit root using all three tests at a significance level < 1%. The paper specifically notes that if the deficit is stationary in levels then a Vector Error Correction model can be applied. As the original author's fails to reject the null he implements a Vector AutoRegression model on the first differenced data. In levels the only other series that I find to be stationary is natural resource revenue. ADF on program expenditure would also reject the null at 5% significance, but would fail to reject it using the other two tests.\n",
    "\n",
    "Looking at the first differenced series, since that's what the paper ultimately ends up using, I also reject the null hypothesis of a unit root for all variables using all tests at a 1% significant *except* program expenditure and deficit using Augmented Dickey Fuller. Those last two tests differ from what's reported in the paper. \n",
    "\n",
    "The paper notes that it uses the Schwarz Information Criterion (SIC) for determining optimal lags in the DF-GLS test. It doesn't specify what it's using in the other two tests. For ADF and DF-GLS I used the Schwarz/Bayesian IC (BIC), [which is just another name for SIC](https://en.wikipedia.org/wiki/Bayesian_information_criterion). Phillips-Perron only uses 1 lag and then Newey-West for a long run variance estimator. I also ran these tests using Akaike IC (AIC) for optimal lags for ADF and DF-GLS, with similar results.\n",
    "\n",
    "Again we can see that using the results with the data error more closely matches the table in the paper, specifically around resource revenue and deficits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Model\n",
    "\n",
    "The conclusions from the paper are based on fitting a [VAR](https://en.wikipedia.org/wiki/Vector_autoregression) to the first differenced data set we've been analyzing above. Let's do that now and compare the results to the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_var(mdfl: pd.DataFrame) -> statsmodels.tsa.vector_ar.var_model.VARResults:\n",
    "    \"\"\"Fit a VAR to the model data.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    mdfl: pd.DataFrame\n",
    "        Input model data\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    statsmodels.tsa.vector_ar.var_model.VarResults\n",
    "        The fitted model\n",
    "    \"\"\"\n",
    "    vec_df = (\n",
    "        model_df_first_diff(mdfl)\n",
    "        .drop(columns='natural_resource_revenue')\n",
    "        .dropna()\n",
    "    )\n",
    "    endog_df = vec_df[[\n",
    "        'nrri', 'nrrd', 'program_expenditure', 'debt_service', 'corporate_income_tax',\n",
    "         'personal_income_tax', 'other_revenue'\n",
    "    ]]\n",
    "    exog_df = vec_df[['ur_lag', 'er_lag', 'cad_usd_lag', 'heritage_dummy']]\n",
    "    model = VAR(endog=endog_df, exog=exog_df, freq='AS')\n",
    "    # Fit the model with 2 lags\n",
    "    results = model.fit(2)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight_significance(val):\n",
    "    \"\"\"Colour code statistical significance.\n",
    "\n",
    "    Takes a scalar and returns a string with\n",
    "    the css property `'color: <color>'` where\n",
    "    color is maroon for 1% significance, \n",
    "    red for 5% significance,\n",
    "    orange for 10%, and black otherwise\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    val: float\n",
    "        The p value of a test\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str:\n",
    "        A formatted colour coded p value\n",
    "    \"\"\"\n",
    "\n",
    "    if val <= 0.01:\n",
    "        color = 'maroon'\n",
    "    elif val <= 0.05:\n",
    "        color = 'red'\n",
    "    elif val <= 0.1:\n",
    "        color = 'orange'\n",
    "    else:\n",
    "        color = 'black'\n",
    "    return f'color: {color}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = fit_var(mdfl)\n",
    "results_err = fit_var(mdfl_err)\n",
    "summary = results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the rows and columns of my parameters to match the paper\n",
    "reindex_cols = [\"program_expenditure\", \"debt_service\", \"corporate_income_tax\", \"personal_income_tax\", \"other_revenue\", \"nrri\", \"nrrd\"]\n",
    "index_order = [\"nrri\", \"nrrd\", \"program_expenditure\", \"debt_service\", \"corporate_income_tax\", \"personal_income_tax\", \"other_revenue\"]\n",
    "reindex_rows = list(chain.from_iterable((f\"L1.{row}\", f\"L2.{row}\") for row in index_order))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the table from the paper:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename=\"img/ferede_tbl_a2.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.params.reindex(index=reindex_rows, columns=reindex_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.pvalues.reindex(index=reindex_rows, columns=reindex_cols).style.applymap(highlight_significance).format(\"{:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_err.params.reindex(index=reindex_rows, columns=reindex_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_err.pvalues.reindex(index=reindex_rows, columns=reindex_cols).style.applymap(highlight_significance).format(\"{:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, my results with the data error included are much closer to the original paper results. Note that without the data error, program spending is shown to rise in response to an increase *or* decrease in natural resource revenue, but only on the second lag (at least at a statistically significant level. That's completely contrary to the main thesis of the paper. Now, given that I've shown with the corrected data set that budget deficits are stationary in levels, maybe a more appropriate form of analysis would have been to use a VECM as the paper states it would have been, but from this I can say that the data error has led to a significant change in the outcome of the analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impulse Response Functions\n",
    "\n",
    "The actual results of the paper involve taking the estimated impulse response functions derived from the VAR model and examining their implications. Given the results above I'm not sure there's a lot of value in reproducing all of the other results of this model, but I do want to at least reproduce the IRFs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def irf_tbl(result: statsmodels.tsa.vector_ar.var_model.VARResults, impulse: str) -> pd.DataFrame:\n",
    "    \"\"\"Show the IRF as in table 3 of the paper.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    result: statsmodels.tsa.vector_ar.var_model.VARResults\n",
    "        The fitted VAR\n",
    "\n",
    "    impulse: str\n",
    "        The impulse function, either an increase or decrease in natural resource revenue\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        A summary table\n",
    "    \"\"\"\n",
    "    irf = result.irf()\n",
    "    irf_stderr = irf.stderr()\n",
    "    irfs = irf.irfs\n",
    "    params = list(results.params.columns)\n",
    "\n",
    "    def _impulse_response(impulse: str, response: str) -> pd.DataFrame:\n",
    "        \"\"\"Get a specific IRF out of the big array.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        impulse: str\n",
    "            The impulse function\n",
    "        response: str\n",
    "            The response function\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        pd.DataFrame\n",
    "            The 3 period IRF\n",
    "        \"\"\"\n",
    "        imp_ind = params.index(impulse)\n",
    "        res_ind = params.index(response)\n",
    "        ir = irfs[:, res_ind, imp_ind]\n",
    "        se = irf_stderr[:, res_ind, imp_ind]\n",
    "        imp_name = response + '_impulse'\n",
    "        se_name = response + '_se'\n",
    "        df = pd.DataFrame({imp_name: ir, se_name: se})\n",
    "        return df.loc[1:3].T\n",
    "\n",
    "    responses = params[2:]\n",
    "    return pd.concat([_impulse_response(impulse, response) for response in responses])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Table 3\n",
    "IMPACTS ON ALBERTAâ€™S BUDGET OF A ONE-DOLLAR INNOVATION IN NON-RENEWABLE-RESOURCE\n",
    "REVENUE (ASYMMETRIC CASE), 1970/71â€“2016/17 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename=\"img/ferede_tbl_3.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "irf_tbl(results, \"nrrd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "irf_tbl(results, \"nrri\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "irf_tbl(results_err, \"nrrd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "irf_tbl(results_err, \"nrri\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same patters as we've seen above, the results with the data error included are pretty close to what the paper reports."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the IRFs\n",
    "Ok, this is the last bit I want to reproduce, just because IRF charts look cool so it would be a shame to leave them out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename=\"img/ferede_fig_3.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.irf().plot(impulse='nrri', response='program_expenditure');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.irf().plot(impulse='nrrd', response='program_expenditure');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_err.irf().plot(impulse='nrri', response='program_expenditure');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_err.irf().plot(impulse='nrrd', response='program_expenditure');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are harder to eyeball because I'm showing the individual responses and the paper is showing the cumulative ones. But again, if I think about what adding up the points in my charts would look like, they end up closer to the data set with the error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "The initial goal of this exercise was to practice my python and econometrics. I've certainly done that over the course of working on it, but as a bonus I've also demonstrated how sensitive results can be to even a single data point (at least when you have relatively few samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix: Raw tables\n",
    "For the purposes of validation, here are the full tables I used to produce both the summary statistics above, as well as all statistical models and tests below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdfl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df_first_diff(mdfl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdfl_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df_first_diff(mdfl_err)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
